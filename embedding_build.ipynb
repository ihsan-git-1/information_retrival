{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jony\\Uni\\IR\\information_retrival\\env\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from core.embeddings import EmbeddingSearcher\n",
    "import ir_datasets\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Variables\n",
    "#### not: current model all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jony\\Uni\\IR\\information_retrival\\env\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "wikiR = \"wikir/en1k/training\"\n",
    "antique = \"antique/test/non-offensive\"\n",
    "antique_train = \"antique/train/split200-train\"\n",
    "\n",
    "choosenDataSet = antique\n",
    "dataset = ir_datasets.load(choosenDataSet)\n",
    "\n",
    "embedding = EmbeddingSearcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each document add and normalize \n",
    "\n",
    "for index,doc in enumerate(dataset.docs_iter()):\n",
    "    embedding.add_document(doc_id=doc.doc_id, text=doc.text,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Trainning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = []\n",
    "train_dataset = ir_datasets.load(antique_train)\n",
    "\n",
    "# Iterate over the dataset and prepare InputExamples\n",
    "for query in train_dataset.queries_iter():\n",
    "    query_id = query.query_id\n",
    "    query_text = query.text\n",
    "    for qrel in train_dataset.qrels_iter():\n",
    "        if qrel.query_id == query_id:\n",
    "            doc = None\n",
    "            for id, text in embedding.documents:\n",
    "                if (id == qrel.doc_id):\n",
    "                    doc = text\n",
    "                    break\n",
    "\n",
    "            label = 0\n",
    "            if (qrel.relevance > 2):\n",
    "                label = 1\n",
    "\n",
    "            train_examples.append(InputExample(\n",
    "                texts=[query_text, doc], label=float(label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model on top of the current model all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 500/1577 [26:15<1:05:37,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.253, 'grad_norm': 1.6056740283966064, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 1000/1577 [52:07<23:42,  2.46s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1916, 'grad_norm': 1.083077311515808, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 1500/1577 [1:21:19<04:51,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1625, 'grad_norm': 0.7994086146354675, 'learning_rate': 3e-06, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1577/1577 [1:25:45<00:00,  3.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 5145.1173, 'train_samples_per_second': 4.903, 'train_steps_per_second': 0.307, 'train_loss': 0.20018289054430355, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    }
   ],
   "source": [
    "# The trained model is now saved to the 'output_path' directory\n",
    "train_dataloader = DataLoader(\n",
    "            train_examples, shuffle=True, batch_size=16)\n",
    "\n",
    "        # Define the loss function\n",
    "train_loss = losses.CosineSimilarityLoss(embedding.model)\n",
    "\n",
    "        # Train the model\n",
    "embedding.model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "                       epochs=1,  # may need to increase this for better performance\n",
    "                       output_path='./output/trained_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Documents Embeddings using the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.build_documents_embeddings()\n",
    "embedding.save(\"antique_embed.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
