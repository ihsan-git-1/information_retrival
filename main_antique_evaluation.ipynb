{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from core.vsm_visualizer import VectorSpaceModel\n",
    "from core.query import QueryHandler\n",
    "from core.embeddings import EmbeddingSearcher\n",
    "import ir_datasets\n",
    "import ir_measures\n",
    "from ir_measures import nDCG, P, Judged, R, AP, RR,AP_IA\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Datasets and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ir_datasets.load(\"antique/test/non-offensive\")\n",
    "vsm = VectorSpaceModel.load(\"antique_state.pkl\")\n",
    "embed = EmbeddingSearcher.load(\"antique_embed.pkl\")\n",
    "query_handler = QueryHandler(vsm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the qrels into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_rows = []\n",
    "\n",
    "for qrel in dataset.qrels_iter():\n",
    "    new_row = {'query_id': qrel.query_id,\n",
    "                   'doc_id': qrel.doc_id, 'relevance': qrel.relevance}\n",
    "    qrels_rows.append(new_row)\n",
    "\n",
    "qrels_table_results = pd.DataFrame(\n",
    "    qrels_rows, columns=['query_id', 'doc_id', 'relevance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Queries without embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afterward', 'alon', 'alreadi', 'alway', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becom', 'besid', 'colombia', 'cri', 'describ', 'egypt', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'germani', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'ireland', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'otherwis', 'perhap', 'peru', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'state', 'thenc', 'thereaft', 'therebi', 'therefor', 'thu', 'togeth', 'twelv', 'twenti', 'unit', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Get queries\n",
    "queries = dataset.queries_iter()\n",
    "\n",
    "query_rows = []\n",
    "for index, (query_id, query_text) in enumerate(queries):\n",
    "    # search for the query\n",
    "    search_results = query_handler.search(query_text,similarity_threshold= 0.001)\n",
    "    for (document, similarity) in search_results:\n",
    "        new_row = {'query_id': query_id,\n",
    "                   'doc_id': document[0], \n",
    "                   'score': similarity}\n",
    "        query_rows.append(new_row)\n",
    "        # retrieval_results.append((query_id,document[0],similarity))\n",
    "\n",
    "\n",
    "query_table_results = pd.DataFrame(\n",
    "    query_rows, columns=['query_id', 'doc_id', 'score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Queries with embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get queries\n",
    "\n",
    "queries = dataset.queries_iter()\n",
    "\n",
    "query_embed_rows = []\n",
    "for index, (query_id, query_text) in enumerate(queries):\n",
    "    # search for the query\n",
    "    search_results = embed.search(query_text,similarity_threshold=0.25)\n",
    "    for (document, similarity) in search_results:\n",
    "        new_row = {'query_id': query_id,\n",
    "                   'doc_id': document[0], \n",
    "                   'score': similarity}\n",
    "        query_embed_rows.append(new_row)\n",
    "        # retrieval_results.append((query_id,document[0],similarity))\n",
    "\n",
    "\n",
    "query_embed_results = pd.DataFrame(\n",
    "    query_embed_rows, columns=['query_id', 'doc_id', 'score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Claculate The Evaluation Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results with embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{AP(rel=3): 0.2934999571497649,\n",
       " R@10: 0.15516703579285385,\n",
       " P@10: 0.46477272727272717,\n",
       " RR(rel=3): 0.7089781417842417}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_measures.calc_aggregate(\n",
    "    [AP(rel=3),\n",
    "    P(rel=1)@10,\n",
    "    R(rel=1)@10,\n",
    "    RR(rel=3),\n",
    "    ], \n",
    "    qrels_table_results,\n",
    "    query_embed_results\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{AP(rel=3): 0.2934999571497649,\n",
    " R@10: 0.15516703579285385,\n",
    " P@10: 0.46477272727272717,\n",
    " RR(rel=3): 0.7089781417842417}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results without embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{AP: 0.22596371811330124,\n",
       " RR: 0.7290534129990595,\n",
       " P@10: 0.3926136363636364,\n",
       " R@10: 0.13217329206111822}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_measures.calc_aggregate(\n",
    "    [AP(rel=1),\n",
    "    P(rel=1)@10,\n",
    "    R(rel=1)@10,\n",
    "    RR(rel=1),\n",
    "    ], \n",
    "    qrels_table_results,\n",
    "    query_table_results\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{AP: 0.22596371811330124,\n",
    " RR: 0.7290534129990595,\n",
    " P@10: 0.3926136363636364,\n",
    " R@10: 0.13217329206111822}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
